from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pydantic_settings import BaseSettings
import os
from supabase import create_client, Client
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
from typing import List, Optional
import asyncio
from concurrent.futures import ThreadPoolExecutor

# --- Configuration using Pydantic Settings ---
class Settings(BaseSettings):
    supabase_url: str
    supabase_key: str
    gemini_api_key: str
    host: str = "0.0.0.0"
    port: int = 8000

    class Config:
        env_file = ".env"

settings = Settings()

# --- Client Initialization ---
supabase: Client = create_client(settings.supabase_url, settings.supabase_key)

genai.configure(api_key=settings.gemini_api_key)

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
try:
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    print(f"gemini-1.5-flash ì‚¬ìš© ë¶ˆê°€, gemini-1.5-pro ì‹œë„: {e}")
    try:
        gemini_model = genai.GenerativeModel('gemini-1.5-pro')
    except Exception as e:
        print(f"gemini-1.5-proë„ ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ ëª¨ë¸ ì‹œë„: {e}")
        gemini_model = genai.GenerativeModel('gemini-pro')

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print("Loading embedding model...")
embedding_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
print("Embedding model loaded.")

app = FastAPI()

# --- Middleware ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Pydantic Models ---
class QueryInput(BaseModel):
    question: str
    top_k: Optional[int] = 3

class QueryResponse(BaseModel):
    answer: str
    relevant_documents: List[dict]

# --- Thread Pool for CPU-bound tasks ---
executor = ThreadPoolExecutor(max_workers=os.cpu_count())

# --- Helper Functions ---
def get_embedding(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
    return embedding_model.encode(text).tolist()

async def check_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ëª©ë¡ í™•ì¸"""
    try:
        models = genai.list_models()
        available_models = []
        for model in models:
            if 'generateContent' in model.supported_generation_methods:
                available_models.append(model.name)
        return available_models
    except Exception as e:
        print(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

# --- API Endpoints ---
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ì‹œ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥"""
    print("=" * 60)
    print("ğŸ¤– RAG ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 60)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = await check_available_models()
    if available_models:
        print("âœ… ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸:")
        for model in available_models[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
            print(f"   - {model}")
    
    print("\nğŸ“‹ Supabase ì„¤ì • í™•ì¸:")
    print("   - 'documents' í…Œì´ë¸”ê³¼ 'vector' extensionì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print("   - í•„ìš”í•œ ê²½ìš° ë‹¤ìŒ SQLì„ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("""
-- 1. pg_vector extension í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS vector;

-- 2. documents í…Œì´ë¸” ìƒì„±
CREATE TABLE IF NOT EXISTS documents (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    content TEXT NOT NULL,
    embedding VECTOR(768),
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 3. ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ í•¨ìˆ˜ ìƒì„±
CREATE OR REPLACE FUNCTION match_documents (
  query_embedding VECTOR(768),
  match_threshold FLOAT,
  match_count INT
)
RETURNS TABLE (
  id BIGINT,
  content TEXT,
  metadata JSONB,
  similarity FLOAT
)
LANGUAGE sql STABLE
AS $$
  SELECT
    d.id,
    d.content,
    d.metadata,
    1 - (d.embedding <=> query_embedding) AS similarity
  FROM documents d
  WHERE 1 - (d.embedding <=> query_embedding) > match_threshold
  ORDER BY similarity DESC
  LIMIT match_count;
$$;
    """)
    print("\nğŸŒ ì„œë²„ ì‹¤í–‰:")
    print(f"   - Backend: http://localhost:{settings.port}")
    print("   - Frontend: index.html íŒŒì¼ì„ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ì£¼ì„¸ìš”")
    print("=" * 60)

@app.post("/query", response_model=QueryResponse)
async def query_documents(query: QueryInput):
    """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
    try:
        # 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
        current_loop = asyncio.get_running_loop()
        query_embedding = await current_loop.run_in_executor(executor, get_embedding, query.question)
        
        # 2. Supabaseì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        try:
            response = supabase.rpc('match_documents', {
                'query_embedding': query_embedding,
                'match_threshold': 0.3,  # ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ ê²°ê³¼ ë°˜í™˜
                'match_count': query.top_k
            }).execute()
            
            top_docs = response.data if response.data else []
        except Exception as db_error:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {db_error}")
            # ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            top_docs = []
        
        # 3. ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ AI ì‘ë‹µ ì œê³µ
        if not top_docs:
            print("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ AI ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.")
            
            # ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ AI ì‘ë‹µ
            general_prompt = f"""ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query.question}

ë‹µë³€:"""
            
            try:
                gemini_response = gemini_model.generate_content(general_prompt)
                answer_text = gemini_response.text
            except Exception as gemini_error:
                print(f"Gemini API ì˜¤ë¥˜: {gemini_error}")
                answer_text = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            return QueryResponse(
                answer=answer_text,
                relevant_documents=[]
            )
        
        # 4. ê´€ë ¨ ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ
        context = "\n\n---\n\n".join([doc['content'] for doc in top_docs])
        
        # RAG ê¸°ë°˜ í”„ë¡¬í”„íŠ¸
        rag_prompt = f"""ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ë¬¸ì„œ ë‚´ìš©:**
{context}

**ì§ˆë¬¸:**
{query.question}

**ì§€ì¹¨:**
- ë°˜ë“œì‹œ ìœ„ì— ì£¼ì–´ì§„ 'ë¬¸ì„œ ë‚´ìš©'ë§Œì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
- ë¬¸ì„œì— ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ë¬¸ì„œì— ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
- ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

**ë‹µë³€:**
"""
        
        try:
            gemini_response = gemini_model.generate_content(rag_prompt)
            answer_text = gemini_response.text
        except Exception as gemini_error:
            print(f"Gemini API ì˜¤ë¥˜: {gemini_error}")
            answer_text = f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì°¸ê³  ë¬¸ì„œ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\n\nì°¸ê³  ë¬¸ì„œ:\n{context[:300]}..."
        
        return QueryResponse(
            answer=answer_text,
            relevant_documents=top_docs
        )
        
    except Exception as e:
        print(f"Query ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        # ì „ì²´ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì œê³µ
        return QueryResponse(
            answer="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            relevant_documents=[]
        )

@app.get("/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    try:
        available_models = await check_available_models()
        return {"available_models": available_models}
    except Exception as e:
        return {"error": f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        # Supabase ì—°ê²° í…ŒìŠ¤íŠ¸
        supabase.table("documents").select("count", count="exact").limit(1).execute()
        db_status = "healthy"
    except:
        db_status = "error"
    
    return {
        "status": "healthy",
        "database": db_status,
        "embedding_model": "loaded",
        "gemini_model": "configured"
    }

@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ - API ìƒíƒœ"""
    return {
        "message": "ğŸ¤– RAG ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!",
        "endpoints": {
            "query": "/query - ì§ˆë¬¸ ì²˜ë¦¬",
            "health": "/health - ì„œë²„ ìƒíƒœ í™•ì¸",
            "models": "/models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=settings.host, port=settings.port)